---
title: "Typical posterior draws"
header:
  image: /assets/images/IMG_0156_resize.jpg
  caption: "Lovely Edmonton"

tags:
  - table of contents
toc: true
toc_label: "Chapters"
toc_icon: "heart"
toc_sticky: true

author_profile: false
share: false
layout: single
---

I feel that for beginners in stan, or even in Bayesian, the typical features of the posterior draws because of:
1. Insufficient warm-up iterations,
2. Insufficient adapt_delta,
3. Insufficient post warm-up iterations,
4. Whether my certain priors can even be estimated
are mysterious.

So I want to take notes on my example of the shape of the posterior distribution when fitting a Panel Markov Swithcing VAR(PMS-VAR) model.

## Model
### Basic model setting
In short, the basic model settings are:

$$
y_{it} = \text{VAR Coef} + \text{MS Coef} + \varepsilon_{it}
$$

, where VAR coefficients are regime-invariate.

In the full version, the model settings are (detailed descriptions in BILLIO et al. (2016): INTERCONNECTIONS BETWEEN EUROZONE AND US BOOMS AND BUSTS USING A BAYESIAN PANEL MARKOV-SWITCHING VAR MODEL):

$$
y_{it} = X_{i0t} \gamma_{i0} + \xi_{i1t} X_{i1t} \gamma_{i1} + \cdots + \xi_{iMt} X_{iMt} \gamma_{iM} + \varepsilon_{it}, \; \varepsilon_{it} \sim N_{K} (0, \Sigma_{i}(\xi_{it}))
$$

, where $X_{i0t}$ is the VAR coefficients which contains the lagged variables of $y_{it}$, $\xi_{i1t} X_{i1t} \gamma_{i1} + \cdots + \xi_{iMt} X_{iKt} \gamma_{iM}$ are the MS coefficients for each variable $$k$$ in regime $$m$$, respectively. Finnally, there are $$K$$ variables in the VAR system.

### Transition setting
BILLIO et al. (2016) implements the covariate method from Kaufmann (2011): K-state switching models with time-varying transition distributions – Does credit growth signal stronger effects of variables on inflation?.

Also, it builds a way to "impose the constraint of a minimum duration of 2 months for the recession phase". However, in stan, it does not support discret variable in the parameter and transformed parameter blocks, so I ignore this part, and only the pure original covariate method from Kaufmann (2014) is used.

$$
P(S_{t} = m | S_{t-1} = l, Z_{t}, \gamma) = \xi_{lm, t} = \frac{exp(Z_{t} \gamma^{z}_{lm} + \gamma_{lm})}
{\sum^{M}_{j=1}exp(Z_{t} \gamma^{z}_{lm} + \gamma_{lm})}
$$

, where $Z_t$ is the covariate. For identification purpose, the reference state is the last regime, M, which means that the coefficients $$\gamma^{z}_{lM}$$ and $$\gamma_{lM}$$are zeros.

Besides, since this is a panel model, it can be extended easily.

### Prior setting
BILLIO et al. (2016) tries hierarchical prior, and from the famous 8 school example, more units in the panel model, the more advantage can be gained. 

1) VAR oefficient

$$
\gamma_{i0} \sim N(\lambda_{0}, \underline{\Sigma_{i0}}),
$$

$$
\lambda_{0} \sim N(\underline{\lambda_{0}}, \underline{\Sigma_{0}}),
$$

$$
i = 1, \cdots, N
$$

2) MS oefficient
For each regime $$m$$, it also has hierarchical priors:

$$
\gamma_{im} \sim N(\lambda_{m}, \underline{\Sigma_{im}}),
$$

$$
\lambda_{m} \sim N(\underline{\lambda_{m}}, \underline{\Sigma_{m}}),
$$

$$
i = 1, \cdots, N,  \; m = 1, \cdots, M
$$

3) Covariance

$$
\Sigma^{-1}_{im} \sim W(\underline{\nu_{im}}, \tau_{m})
$$

$$
\tau^{-1}_{m} \sim W(\underline{\nu_{m}}, \underline{\tau_{m}})
$$

I know that ppl suggest to decompose the covariance and use LKJ prior recently, however, LKJ cannot be built hierarchial structure, and if the number of units is large, LKJ prior will suffer from divergents.

From the perspective of coding, in the documentation of stan, it suggests the reparameterization of Wishart\inverse Wishart. I'm not sure if it is OK if I code the global level as inverse Wishart and the individual level as Wishart to avoid inverse $\tau^{-1}_{m}$. I've tried the combinations, such as IW+W, W+W, IW+IW. There was no issue in DGP, however, it is more complicated in the real data.

4) Covariate
   
$$
\gamma^{lm}_{i} = (\gamma^{z}_{i, lm}, \gamma_{i, lm})
$$

$$
\gamma^{lm}_{i} \sim N(\psi, \tau_{i})
$$

$$
\psi \sim N(\underline{psi}, \underline{\tau}), \; i = 1, \cdots, N, \; m = 1, \cdots, M-1
$$

5) Hyper-parameter

VAR coef:

$$
\underline{\lambda_{0}} = 0, \; \underline{\Sigma_{i0}} = I,  \; \underline{\Sigma_{0}} = 10 I
$$

MS coef:

$$
\underline{\lambda_{m}} = 0, \; \underline{\Sigma_{im}} = I,  \; \underline{\Sigma_{m}} = 10 I
$$

Covariance:

$$
\underline{\nu_{im}} = K + 2, \; \underline{\nu_{m}} = K + 2, \; \underline{\tau_m} = 10
$$

Covariate coef:

$$
\underline{\psi} = 0, \; \tau_{i} = I, \underline{\tau} = 10 I
$$

## DGP setting
For the DGP, I set $$N=2$$ units, $$K=2$$ variables, $$M=2$$ regimes, and use a random series as covariate.

Also, I set $$T=50$$, lag length $$P = 1$$.

Each unit has the same transition matrix, $$p11 = 0.7$$, 

My DGP follows what the prior structure says, and with tighter range:

$$
\underline{\lambda_0} = \texttt{[0.5 -0.3 0.2 0.4]}
$$<br>
$$
\underline{\Sigma_{0}} = \texttt{diag(0.1, K*K*P)}
$$<br>
$$
\underline{\Sigma_{i, 0}} = \texttt{replicate(N, diag(0.1, K*K*P), simplify = FALSE)}
$$<br>
$$
\underline{\lambda_{m = 1}} = \texttt{rep(-1, K)}, \; \underline{\lambda_{m = 2}} = \texttt{rep(1, K)}
$$<br>
$$
\underline{\Sigma_{m}} = \texttt{diag(0.1, K)}
$$<br>
$$
\underline{\Sigma_{i, m}} = \texttt{diag(0.1, K)}
$$<br>
$$
\underline{\Sigma_{i, 0}} = \texttt{replicate(N, diag(0.1, K), simplify = FALSE)}
$$<br>
$$
\underline{\nu_{i, m}} = \texttt{rep(50, N)}
$$<br>
$$
\underline{\psi} = \texttt{c(-1, 1)}
$$<br>
$$
\underline{\tau} = \texttt{diag(0.1, 2)}
$$<br>
$$
\underline{\tau{i}} = \texttt{replicate(N, diag(0.1, K), simplify = FALSE)}
$$

The covariate is generated by rnorm with mean = 0 and sd = 0.1.

By doing the above, I think I do not control for the true "need to be estimated" parameters, but through hyper-parameters which gives a little bit more variations to the "true" parameter values.

## Typical shape of posterior draws

In the above model settings, we can see that the VAR coefs are regime-invariate, so if we do not impose restrictions on the ordering of MS coefs, we can only check the diagonose such as Rhat and Ess in $$\gamma_{i0}$$ and $$\texttt{lp__}$$, the rest parameters will suffer from label switching.

The coding structure is that gamma_i0, gamma_i1 and gamma_2[n,k] means for unit n and variable k, and i1 for regime 1.

### Case 1: Successful draws

Basic stan(Cmdstanr) settings: <br>
adapt_delta = 0.8<br>
iter_warmup = 2000<br>
iter_sampling = 1000<br>
n.chains = 4<br>
thin = 1<br>
max_treedepth = 10

|  |True Value| variable      |   mean | median |    sd  |  mad   |  q5    |  q95     |rhat    |ess_bulk | ess_tail|
|  |  | <chr>         |  <dbl> |  <dbl> | <dbl>  | <dbl>  | <dbl>  |  <dbl>   | <dbl>  |  <dbl>  |  <dbl>|
|--|--|---------------|--------|--------|--------|--------|--------|----------|--------|---------|--------|
|1 |-0.102| gamma_i0[1,1] |-0.130  | -0.131 | 0.0632 | 0.0624 | -0.235 | -0.0267  |  1.00  |  4018.  |  3690.|
|2 |-0.1095| gamma_i0[2,1] |-0.117  | -0.117 | 0.0933 | 0.0908 | -0.269 |  0.0345  |  1.00  |  4241.  |  3417.|
|3 |-0.1650| gamma_i0[1,2] |-0.0600 | -0.0588| 0.0506 | 0.0501 | -0.145 |  0.0213  |  1.00  |  4183.  |  3347.|
|4 |-0.1265| gamma_i0[2,2] |-0.0730 | -0.0737| 0.0497 | 0.0488 | -0.153 |  0.00898 |  1.00  |  3727.  |  3680.|
|5 |0.3405| gamma_i0[1,3] | 0.313  |  0.310 | 0.0526 | 0.0501 |  0.232 |  0.402   |  1.00  |  4055.  |  3514.|
|6 |0.2763| gamma_i0[2,3] | 0.351  |  0.349 | 0.0911 | 0.0883 |  0.203 |  0.503   |  1.00  |  3915.  |  3592.|
|7 |0.7169| gamma_i0[1,4] | 0.723  |  0.724 | 0.0418 | 0.0400 |  0.654 |  0.791   |  1.00  |  4100.  |  3675.|
|8 |0.5986| gamma_i0[2,4] | 0.582  |  0.582 | 0.0489 | 0.0478 |  0.503 |  0.663   |  1.00  |  3922.  |  3402.|
|--|----------|----------|--------|--------|--------|--------|--------|----------|--------|---------|--------|
|1 |-1.5429 |gamma_i1[1,1] |-1.61  | -1.61 | 0.156 | 0.150  | -1.86 | -1.35   | 1.00    | 4304.    | 3277.|
|2 |-1.0025 |gamma_i1[2,1] |-1.13  | -1.13 | 0.161 | 0.153  | -1.40 | -0.875  | 1.00    | 3970.    | 3790.|
|3 |-1.4522 |gamma_i1[1,2] |-1.33  | -1.33 | 0.103 | 0.0989 | -1.50 | -1.16   | 1.00    | 4120.    | 3902.|
|4 |-1.3225 |gamma_i1[2,2] |-1.30  | -1.31 | 0.145 | 0.134  | -1.53 | -1.07   | 1.00    | 4157.    | 3719.|
|--|-------|---------------|--------|--------|--------|--------|--------|----------|--------|---------|--------|
|1 |1.5134 |gamma_i2[1,1] | 1.34   | 1.34  | 0.129 | 0.125 | 1.12  | 1.54   | 1.00    | 3841.    | 3213.|
|2 |0.5887 |gamma_i2[2,1] | 0.610  | 0.609 | 0.159 | 0.159 | 0.349 | 0.870  | 1.00    | 3848.    | 3513.|
|3 |1.3679 |gamma_i2[1,2] | 1.28   | 1.28  | 0.201 | 0.196 | 0.943 | 1.60   | 1.00    | 4218.    | 3170.|
|4 |1.4717 |gamma_i2[2,2] | 1.61   | 1.62  | 0.161 | 0.161 | 1.35  | 1.88   | 1.00    | 4058.    | 3718.|
|--|--|------|--------|--------|--------|--------|--------|----------|--------|---------|--------|
|1 |         | lp__| -273.  | -272.  | 5.71   | 5.82   | -282.  | -264.    | 1.00   | 1380.   | 2653.|

These parameters are basically aligns with the true values from DGP.

Also, there is no warnings.
```r
$num_divergent
[1] 0 0 0 0

$num_max_treedepth
[1] 0 0 0 0

$ebfmi
[1] 0.8609319 0.9688577 0.9788011 0.8950120
```

![Smithsonian Image]({{ site.url }}{{ site.baseurl }}/assets/images/post1/su_lp.png)
{: .image-right}

```r
Parameter with minimum ESS: gamma_i0[2,2] at index 4 with ESS value: 3726.934 
Parameter with maximum Rhat: gamma_i0[2,1] at index 2 with Rhat value: 1.001201 
Checking sampler transitions treedepth.
Treedepth satisfactory for all transitions.

Checking sampler transitions for divergences.
No divergent transitions found.

Checking E-BFMI - sampler transitions HMC potential energy.
E-BFMI satisfactory.

Rank-normalized split effective sample size satisfactory for all parameters.

Rank-normalized split R-hat values satisfactory for all parameters.

Processing complete, no problems detected.
```
![Smithsonian Image]({{ site.url }}{{ site.baseurl }}/assets/images/post1/su_gamma_i0.png)
{: .image-right}

### Case 2: Insufficient warm-up iterations

I modified the previous 2000 warm-up to 100 with the same adapt_delta, and we will see:



### Insufficient max_treedepth

#### Less than default(<=10)

### Insufficient adapt_delta

#### adapt_delta and warm-up

### Some questions

### The prior cannot be estimated solid at all?



This post should display a **header image**, if the theme supports it.

Non-square images can provide some unique styling issues.

## HTML Elements

Below is just about everything you'll need to style in the theme. Check the source code to see the many embedded elements within paragraphs.

## Body text

Lorem ipsum dolor sit amet, test link adipiscing elit. **This is strong**. Nullam dignissim convallis est. Quisque aliquam.

![Smithsonian Image]({{ site.url }}{{ site.baseurl }}/assets/images/3953273590_704e3899d5_m.jpg)
{: .image-right}

*This is emphasized*. Donec faucibus. Nunc iaculis suscipit dui. 53 = 125. Water is H2O. Nam sit amet sem. Aliquam libero nisi, imperdiet at, tincidunt nec, gravida vehicula, nisl. The New York Times (That’s a citation). Underline.Maecenas ornare tortor. Donec sed tellus eget sapien fringilla nonummy. Mauris a ante. Suspendisse quam sem, consequat at, commodo vitae, feugiat in, nunc. Morbi imperdiet augue quis tellus.

HTML and CSS are our tools. Mauris a ante. Suspendisse quam sem, consequat at, commodo vitae, feugiat in, nunc. Morbi imperdiet augue quis tellus. Praesent mattis, massa quis luctus fermentum, turpis mi volutpat justo, eu volutpat enim diam eget metus.

### Blockquotes

> Lorem ipsum dolor sit amet, test link adipiscing elit. Nullam dignissim convallis est. Quisque aliquam.

## List Types

### Ordered Lists

1. Item one
   1. sub item one
   2. sub item two
   3. sub item three
2. Item two
3. 

<script src="https://giscus.app/client.js"
        data-repo="steakdream/steakdream.github.io"
        data-repo-id="R_kgDOODkdGg"
        data-category="General"
        data-category-id="DIC_kwDOODkdGs4Cog3q"
        data-mapping="pathname"
        data-strict="1"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="bottom"
        data-theme="preferred_color_scheme"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script>
